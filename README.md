# HPC Software Stack Testing Framework

The HPC Software stack testing framework (hpcswtest) is used in the INL Scientific Computing Department to test the basic sanity and integrity of the HPC Software stack (Compilers, MPI, Numerical libraries and Applications) and to quickly discover hard failures. As a by-product it will indirectly check the HPC infrastructure (network, PBS and licensing servers). Hpcswtest is primarily written in c++11, with some supporting scripts written in python2. A json file defines all the tests to be run (i.e typically each line contains the module name and version), Job scheduler scripts for the tests are generated and submitted to the scheduling system (PBS pro and SLURM are supported). When the tests have complete a python script (i.e hpcswtest_report.py) is provided to check the results and generate a report.
An example json file is provided (hpcswtest.json_def).

This UTSA revision was developed by the Research Computing Support group at the University of Texas at San Antonio for testing applications installed on the HPC cluster named Arc. This revision keeps the original testing cases for the applications installed on both the HPC cluster at INL Scientific Computing Department and the Arc HPC cluster at UTSA. It introduces the GenericTest class to handle all the applications other than the ones included in the original revision. With the GenericTest class, adding a new application does not require creating a corresponding C++ class and re-compiling the entire framework as in the INL revision.

Tests Supported
---------------
Besides the ones included in the INL revision such as MPI libraries, Compilers, abaqus, matlab, ansys, lsdyna, lammps, nwchem, python2 and python3, the UTSA revison included anaconda, miniconda, java, R, singularity, autodock, bcl2fastq, bcl2fastq2, fds, fsl, geos, glpk, homer, columbus, cellranger, mathematica, meep, namd, blast, sratoolkit, opensees, orca, parallel, perl, salmon, samtools, sbt, scala3, spaceranger, subread, trimgalore, cmake, gdal, gmp, harminv, hdf5, jpeglib, proj, sqlite, squashfs, tcl, tiff, valgrind, xalt, and yaml-cpp. All the new added applications are handled by the GenericTest class without re-compiling the code.

Building Dependencies
---------------------
Software was built with GCC 4.9.3 compilers and boost c++ libraries version 1.60. Python 2.7.12+ required.


Building Procedure
------------------
Modify Makefile as appropriate, and type

make

To build SLURM version, modify Makefile, add -DSLURM to CPPFLAGS, then make.


Environmental variables
-----------------------
HPCSWTEST_QUEUE - Define job scheduling queue to use.

HPCSWTEST_BASE_DIR - Directory location of default json file defining the tests to run (hpcswtest.json_def) (If hpcswtest.json is
contained in your current working directory then this environmental variable will be ignored and hpcswtest.json will be used to define what tests to run.)

Editing the report generator Python script
----------------
The report generator is written in Python2. A testing pattern entry is needed in the Python script for every application that needs to be tested as in the configuration file. Take the example of perl above; the entry in the script looks like following:
```
                      "perl": {
                                 "file_patterns": {
                                                   "pbs_stdout": ["Hello, World!"]
                                                  },
                                 "files_exist": [],
                                 "check_file_sizes": []
                                },
```
Important: the application name here, "perl" must match the module name in the configuration file. 
In this example, the report generation will pass the testing for perl if it sees the pattern "Hello, World!" which is the output of the perl sample code in the output file, for instance perl_55_0.o47865 generated by Slurm.

Testing Procedure
----------------
Create a directory, execute hpcswtest executable inside created directory. Modify the "system_configuration" section in the default json file. Set the environmental variable, HPCSWTEST_BASE_DIR to location of hpcswtest.json_def file and HPCSWTEST_QUEUE to the queue you want to use.
If file "hpcswtest.json" is not contained in your current working directory then the default json file (i.e hpcswtest.json_def) will be used to execute tests.

When all tests have completed, run hpcswtest_report.py inside your current working directory to create a report showing what tests passed/failed.


Template variables
------------------
There are a couple of template variables defined in the input json file (hpcswtest.json_def) and report script (hpcswtest_report.py) for your convenience.

INPUT_NAME - Will substitute the appropriate input file name generated internally for the testing framework (json file).
JOB_NAME - Will subsitute the appropriate scheduler job name generated internally by the testing framework (json file).
pbs_stdout - Will substitute the appropriate scheduler stdout file name generated internally by the testing framework (hpcswtest_report.py).
pbs_stderr - Will substitute the appropriate scheduler stderr file name generated internally by the testing framework (hpcswtest_report.py).


Json Input file (hpcswtest.json_def) file format
------------------------------------------------
At the top of the json file contains a section called "system configuration", modify it for your environment, identifying 
what clusters to test, the names of login-nodes for each cluster and if using PBS pro as your scheduler, the chunk-size for
your processors. The other sections of the json file correspond to the clusters you will be testing.
Most application tests can use the provided automated submission scripts to generate the scheduler job syntax or have the testing framework generate the scheduler syntax directly for you. If "run_script" is defined then the defined run_script will be used to generate the job scheduler script syntax, otherwise the framework will generate the job run scripts directly, using the "mpi_cmd_name", "mpi_cmd_args", "exe_name" and "exe_args" definitions.

The configuration file is written in json format. It can be named as hpcswtest.json_def and saved in the location indicated by the environmental variable HPCSWTEST_BASE_DIR, or it can be named as hpcswtest.json and saved it in your current working directory. 
For example, the entry for perl in the configuration file looks like following:
```
"perl":
                                [
                                 {"module_name": "perl", "module_version": "5.26.3","working_dir":"test-cases/perl","exe_name": "perl test.pl", "exe_args": ""},
                                 {"module_name": "perl", "module_version": "5.34.0","working_dir":"test-cases/perl","exe_name": "perl test.pl", "exe_args": ""}
                                ],
```
In this case, two versions of perl will be tested, version 5.26.3 and 5.34.0. The "working_dir" keyword will direct the testing command suggested by "exe_name" and "exe_args" to run in directory test-cases/perl. The sample per code needs to be put in test-cases/perl under the directory where HPCSWTEST_BASE_DIR points to.


Testing verification and checks
-------------------------------
The script hpcswtest_report.py is used to check the test results and generate a report. The following types of checks can be defined in hpcswtest_report.py (Check for regular expression pattern(s) in file(s), check if file exists and check the file size of file(s)). These checks can be defined in the check_file_patterns python dictionary defined at the top of the hpcswtst_report.py file. (See the section Template variables for information on template variables such as pbs_stdout).


Troubleshooting
---------------
If you get test failures you can check the *.log files to see what went wrong. There is a single log file for each application.
To re-run a failed test, create a json file (hpcswtest.json) in your current working directory containing the tests you want to run. (Note if hpcswtest.json exists in your testing directory the default hpcswtest json file (hpcswtest.json_def) is not used.)


This project is supported by [Idaho National Laboratory](https://www.inl.gov/).



### Other Software


[Idaho National Laboratory](https://www.inl.gov/) is a cutting edge research facility which is a constantly producing high quality research and software. Feel free to take a look at our other software and scientific offerings at:



[Primary Technology Offerings Page](https://www.inl.gov/inl-initiatives/technology-deployment)



[Supported Open Source Software](https://github.com/idaholab)



[Raw Experiment Open Source Software](https://github.com/IdahoLabResearch)



[Unsupported Open Source Software](https://github.com/IdahoLabCuttingBoard)



### License 



Copyright 2016 Battelle Energy Alliance, LLC



Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.

You may obtain a copy of the License at



  http://www.apache.org/licenses/LICENSE-2.0



Unless required by applicable law or agreed to in writing, software

distributed under the License is distributed on an "AS IS" BASIS,

WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.

See the License for the specific language governing permissions and

limitations under the License.
